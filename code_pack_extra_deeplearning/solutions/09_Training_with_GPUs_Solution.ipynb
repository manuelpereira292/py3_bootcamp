{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9: Exercise solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../course/common.py') as fin:\n",
    "    exec(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../course/matplotlibconf.py') as fin:\n",
    "    exec(fin.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Exercise 2 of Lab 8](8_NLP_and_Text_Data.ipynb#Exercise-2) we introduced a model for sentiment analysis of the [IMDB](www.imdb.com) dataset provided in Keras. \n",
    "\n",
    "- Reload that dataset and prepare it for training a model:\n",
    "    - choose vocabulary size\n",
    "    - pad the sequences to a fixed length\n",
    "- define a function `recurrent_model(vocab_size, maxlen)` similar to the `convolutional_model` function defined earlier. The function should return a recurrent model.\n",
    "- Train the model on 1 CPU and measure the training time\n",
    "> TIP: This is currently broken. There's an [issue](https://github.com/tensorflow/tensorflow/issues/26245) open about it. The model definition seems to ignore the context setter on the CPU. Just skip this point for now.\n",
    "- Train the model on 1 GPU and measure the training time\n",
    "- Train the model on a machine with more than 1 GPU using `multi_gpu_model` or even better using distribution strategy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size= 10000\n",
    "maxlen=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = \\\n",
    "    imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_model(vocab_size, maxlen):\n",
    "    print(\"Defining recurrent model\")\n",
    "    t0 = time()\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, input_length=maxlen))\n",
    "    model.add(LSTM(64, dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    print(\"{:0.3f} seconds.\".format(time() - t0))\n",
    "\n",
    "    print(\"Compiling the model...\")\n",
    "    t0 = time()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(\"{:0.3f} seconds.\".format(time() - t0))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broken in TF 2.0 alpha release\n",
    "# with tf.device('cpu:0'):\n",
    "#    model = recurrent_model(vocab_size, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training recurrent CPU model...\")\n",
    "# t0 = time()\n",
    "# model.fit(X_train_pad, y_train,\n",
    "#           batch_size=1024,\n",
    "#           epochs=2,\n",
    "#           shuffle=True)\n",
    "# print(\"{:0} seconds.\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining recurrent model\n",
      "0.710 seconds.\n",
      "Compiling the model...\n",
      "0.094 seconds.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('gpu:0'):\n",
    "    model = recurrent_model(vocab_size, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training recurrent GPU model...\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 3s 110us/sample - loss: 0.6557 - accuracy: 0.6470\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 1s 47us/sample - loss: 0.4229 - accuracy: 0.8118\n",
      "4.6133668422698975 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training recurrent GPU model...\")\n",
    "t0 = time()\n",
    "model.fit(X_train_pad, y_train,\n",
    "          batch_size=1024,\n",
    "          epochs=2,\n",
    "          shuffle=True)\n",
    "print(\"{:0} seconds.\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGPU = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining recurrent model\n",
      "0.373 seconds.\n",
      "Compiling the model...\n",
      "0.095 seconds.\n"
     ]
    }
   ],
   "source": [
    "model = recurrent_model(vocab_size, maxlen)\n",
    "\n",
    "model = multi_gpu_model(model, NGPU, cpu_relocation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training recurrent GPU model on 2 GPUs ...\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 2s 87us/sample - loss: 0.6817 - accuracy: 0.6296\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 2s 65us/sample - loss: 0.4969 - accuracy: 0.7808\n",
      "5.124483823776245 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training recurrent GPU model on {} GPUs ...\".format(NGPU))\n",
    "t0 = time()\n",
    "model.fit(X_train_pad, y_train,\n",
    "          batch_size=1024*NGPU,\n",
    "          epochs=2,\n",
    "          shuffle=True)\n",
    "print(\"{:0} seconds.\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining recurrent model\n",
      "0.330 seconds.\n",
      "Compiling the model...\n",
      "1.180 seconds.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = recurrent_model(vocab_size, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training recurrent GPU model on 2 GPUs ...\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.6875 - accuracy: 0.5981\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5751 - accuracy: 0.7424\n",
      "8.852 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training recurrent GPU model on {} GPUs ...\".format(NGPU))\n",
    "t0 = time()\n",
    "model.fit(X_train_pad, y_train,\n",
    "          batch_size=1024*NGPU,\n",
    "          epochs=2,\n",
    "          shuffle=True)\n",
    "print(\"{:0.3f} seconds.\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Model parallelism_ is a technique used for models too large to fit in the memory of a single GPU. While this is is not the case for the model we developed in Exercise 1, it is still possible to distribute the model across multiple GPUs using the with context setter. Define a new model with the following architecture:\n",
    "\n",
    "1. Embedding\n",
    "- LSTM\n",
    "- LSTM\n",
    "- LSTM\n",
    "- Dense\n",
    "\n",
    "Place layers 1 and 2 on the first GPU, layers 3 and 4 on the second GPU and the final Dense layer on the CPU.\n",
    "\n",
    "Train the model and see if the performance improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.663 seconds.\n",
      "Compiling the model...\n",
      "0.133 seconds.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "with tf.device('gpu:0'):\n",
    "    model.add(Embedding(input_dim=vocab_size,\n",
    "                        output_dim=100,\n",
    "                        input_length=maxlen))\n",
    "    model.add(LSTM(64, dropout=0.2,\n",
    "                   return_sequences=True))\n",
    "with tf.device('gpu:1'):\n",
    "    model.add(LSTM(64, dropout=0.2,\n",
    "                   return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.2))\n",
    "with tf.device('cpu:0'):\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"{:0.3f} seconds.\".format(time() - t0))\n",
    "\n",
    "\n",
    "print(\"Compiling the model...\")\n",
    "t0 = time()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"{:0.3f} seconds.\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distributed recurrent model...\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 3s 124us/sample - loss: 0.5996 - accuracy: 0.6692\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 3s 102us/sample - loss: 0.4149 - accuracy: 0.8112\n",
      "7.637561559677124 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training distributed recurrent model...\")\n",
    "t0 = time()\n",
    "model.fit(X_train_pad, y_train,\n",
    "          batch_size=1024,\n",
    "          epochs=2,\n",
    "          shuffle=True)\n",
    "print(\"{:0} seconds.\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "title": "Training with GPUs Exercises Solutions"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
